# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: False
# Url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# Path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
device_target: "Ascend"
device_id: 0
need_modelarts_dataset_unzip: False
modelarts_dataset_unzip_name: ""

# ==============================================================================
# dataset_config
random_seed: 50
epochs: 6
batch_size: 128
pre_train_dataset: "/home/workspace/dataset_menu/train.tok.clean.bpe.32000.en.mindrecord"
fine_tune_dataset: ""
test_dataset:  ""
valid_dataset: ""
dataset_sink_mode: true
input_mask_from_dataset: False

# model_config
seq_length: 51
vocab_size: 32320
hidden_size: 1024
num_hidden_layers: 4
intermediate_size: 4096
hidden_dropout_prob: 0.2
attention_dropout_prob: 0.2
initializer_range: 0.1
label_smoothing: 0.1
beam_width: 2
length_penalty_weight: 0.6
max_decode_length: 50

# loss_scale_config
init_loss_scale: 65536
loss_scale_factor: 2
scale_window: 1000

# learn_rate_config
optimizer: "adam"
lr: 0.002 # 2e-3
lr_scheduler: "WarmupMultiStepLR"
lr_scheduler_power: 0.5
warmup_lr_remain_steps: 0.666
warmup_lr_decay_interval: -1
decay_steps: 4
decay_start_step: -1
warmup_steps: 200
min_lr: 0.000001 #1e-6

# checkpoint_options
existed_ckpt: ""
save_ckpt_steps: 3452
keep_ckpt_max: 6
ckpt_prefix: "gnmt"
ckpt_path: "text_translation"

# export option
file_name: "gnmt_v2"
file_format: "MINDIR"
vocab_file: ""
bpe_codes: ""

---

# Help description for each configuration
enable_modelarts: "Whether training on modelarts, default: False"
data_url: "Url for modelarts"
train_url: "Url for modelarts"
data_path: "The location of the input data."
output_path: "The location of the output file."
device_target: 'Target device type'

file_name: "output file name."
file_format: "file format, choices in ['AIR', 'ONNX', 'MINDIR']"
infer_config: "gnmt_v2 config file"
vocab_file: "existed checkpoint address."
bpe_codes: "bpe codes to use."