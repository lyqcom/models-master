# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: False
# Url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# Path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
device_target: "Ascend"
enable_profiling: False

modelarts_dataset_unzip_name: None
# ==============================================================================
#train-related
is_distributed: 0
rank_id: 0
train_data_dir: ''
batch_size: 32
num_epochs: 20
keep_checkpoint_max: 20
#eval-related
eval_batch_size: 32
test_data_dir: ''
checkpoint_path: None
# logging-related
log_interval: 100
pre_checkpoint_path: ''
ckpt_path: "outputs/"
ckpt_interval: None
is_save_on_master: 0
# dataset-related
mindrecord_dir: ''
data_root: ''
annotation_file: ''
val_data_root: ''
val_annotation_file: ''
data_json: ''
go_shift: 1
characters_dictionary: {"pad_id": 0, "go_id": 1, "eos_id": 2, "unk_id": 3}
labels_not_use: ['%#�?%', '%#背景#%', '%#不识�?%', '#%不识�?#', '%#模糊#%', '%#模糊#%']
vocab_path: "./general_chars.txt"
# model-related
img_width: 512
img_height: 128
channel_size: 3
conv_out_dim: 384
encoder_hidden_size: 128
decoder_hidden_size: 128
decoder_output_size: 10000
dropout_p: 0.1
max_length: 64
attn_num_layers: 1
teacher_force_ratio: 0.5
#optimizer-related
lr: 0.0008
adam_beta1: 0.5
adam_beta2: 0.999
loss_scale: 1024

#export-related
file_name: "crnn-seq2seq-ocr"
file_format: "MINDIR"

#310 infer-related
pre_result_path: './preprocess_Result'
post_result_path: './result_Files'

---

# Help description for each configuration
enable_modelarts: "Whether training on modelarts, default: False"
data_url: "Url for modelarts"
train_url: "Url for modelarts"
data_path: "The location of the input data."
output_path: "The location of the output file."
device_target: 'Target device type'
enable_profiling: 'Whether enable profiling while training, default: False'

is_distributed: 'Distribute train or not, 1 for yes, 0 for no. Default: 0'
rank_id: "Local rank of distributed. Default: 0"
train_data_dir: "Train dataset directory."

log_interval: "Logging interval steps. Default: 100"
ckpt_path: "Checkpoint save location. Default: outputs/"
pre_checkpoint_path: "Checkpoint save location."
ckpt_interval: "Save checkpoint interval. Default: None"
is_save_on_master: "Save ckpt on master or all rank, 1 for master, 0 for all ranks. Default: 0"

test_data_dir: "Test Dataset path"
checkpoint_path: "Checkpoint of AttentionOCR (Default:None)."



