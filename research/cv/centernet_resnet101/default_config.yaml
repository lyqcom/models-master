# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: False
# Url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# Path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
device_target: "Ascend"
enable_profiling: False

# ==============================================================================
# prepare *.mindrecord* data
coco_data_dir: ""
mindrecord_dir: ""  # also used by train.py
mindrecord_prefix: "coco_det.train.mind"

# train related
save_result_dir: ""
device_id: 0
device_num: 1

distribute: 'false'
need_profiler: "false"
profiler_path: "./profiler"
epoch_size: 1
train_steps: -1
enable_save_ckpt: "true"
do_shuffle: "true"
enable_data_sink: "true"
data_sink_steps: -1
save_checkpoint_path: ""
load_checkpoint_path: ""
save_checkpoint_steps: 458
save_checkpoint_num: 1

# val related
data_dir: ""
run_mode: "test"
enable_eval: "true"
visual_image: "false"

# export related
export_load_ckpt: ''
export_format: ''
export_name: ''

# 310 infer
val_data_dir: ''
predict_dir: ''
result_path: ''
label_path: ''
meta_path: ''
save_path: ''

dataset_config:
    num_classes: 80
    max_objs: 128
    input_res_train: [512, 512]
    output_res: [128, 128]
    input_res_test: [680, 680]
    rand_crop: True
    shift: 0.1
    scale: 0.4
    down_ratio: 4
    aug_rot: 0.0
    rotate: 0
    flip_prop: 0.5
    color_aug: True
    coco_classes: ['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
                   'train', 'truck', 'boat', 'traffic light', 'fire hydrant',
                   'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',
                   'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
                   'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
                   'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
                   'kite', 'baseball bat', 'baseball glove', 'skateboard',
                   'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
                   'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
                   'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
                   'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
                   'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
                   'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
                   'refrigerator', 'book', 'clock', 'vase', 'scissors',
                   'teddy bear', 'hair drier', 'toothbrush']
    mean: np.array([0.40789654, 0.44719302, 0.47026115], dtype=np.float32)
    std: np.array([0.28863828, 0.27408164, 0.27809835], dtype=np.float32)
    eig_val: np.array([0.2141788, 0.01817699, 0.00341571], dtype=np.float32)
    eig_vec: np.array([[-0.58752847, -0.69563484, 0.41340352],
                        [-0.5832747, 0.00994535, -0.81221408],
                        [-0.56089297, 0.71832671, 0.41158938]], dtype=np.float32)

net_config:
    num_stacks: 1
    down_ratio: 4
    head_conv: 64
    num_classes: 80
    block_class: [3, 4, 23, 3]
    dense_wh: False
    norm_wh: False
    cat_spec_wh: False
    reg_offset: True
    hm_weight: 1
    off_weight: 1
    wh_weight: 0.1
    mse_loss: False
    reg_loss: 'l1'

train_config:
    batch_size: 32
    loss_scale_value: 1024
    optimizer: 'Adam'
    lr_schedule: 'MultiDecay'
    Adam:
        weight_decay: 0.0
        decay_filter: "lambda x: x.name.endswith('.bias') or x.name.endswith('.beta') or x.name.endswith('.gamma')"
    PolyDecay:
        learning_rate: 0.0005  # 5e-4
        end_learning_rate: 0.0000005  # 5e-7
        power: 5.0
        eps: 0.0000001  # 1e-7
        warmup_steps: 2000
    MultiDecay:
        learning_rate: 0.00048  # 4.8e-4
        eps: 0.0000001  # 1e-7
        warmup_steps: 2000
        multi_epochs: [290, 320]
        factor: 10

eval_config:
    SOFT_NMS: True
    keep_res: True
    multi_scales: [1.0]
    K: 100
    score_thresh: 0.3
    valid_ids: [
      1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13,
      14, 15, 16, 17, 18, 19, 20, 21, 22, 23,
      24, 25, 27, 28, 31, 32, 33, 34, 35, 36,
      37, 38, 39, 40, 41, 42, 43, 44, 46, 47,
      48, 49, 50, 51, 52, 53, 54, 55, 56, 57,
      58, 59, 60, 61, 62, 63, 64, 65, 67, 70,
      72, 73, 74, 75, 76, 77, 78, 79, 80, 81,
      82, 84, 85, 86, 87, 88, 89, 90]
    color_list: [0.000, 0.800, 1.000,
                 0.850, 0.325, 0.098,
                 0.929, 0.694, 0.125,
                 0.494, 0.184, 0.556,
                 0.466, 0.674, 0.188,
                 0.301, 0.745, 0.933,
                 0.635, 0.078, 0.184,
                 0.300, 0.300, 0.300,
                 0.600, 0.600, 0.600,
                 1.000, 0.000, 0.000,
                 1.000, 0.500, 0.000,
                 0.749, 0.749, 0.000,
                 0.000, 1.000, 0.000,
                 0.000, 0.000, 1.000,
                 0.667, 0.000, 1.000,
                 0.333, 0.333, 0.000,
                 0.333, 0.667, 0.333,
                 0.333, 1.000, 0.000,
                 0.667, 0.333, 0.000,
                 0.667, 0.667, 0.000,
                 0.667, 1.000, 0.000,
                 1.000, 0.333, 0.000,
                 1.000, 0.667, 0.000,
                 1.000, 1.000, 0.000,
                 0.000, 0.333, 0.500,
                 0.000, 0.667, 0.500,
                 0.000, 1.000, 0.500,
                 0.333, 0.000, 0.500,
                 0.333, 0.333, 0.500,
                 0.333, 0.667, 0.500,
                 0.333, 1.000, 0.500,
                 0.667, 0.000, 0.500,
                 0.667, 0.333, 0.500,
                 0.667, 0.667, 0.500,
                 0.667, 1.000, 0.500,
                 1.000, 0.000, 0.500,
                 1.000, 0.333, 0.500,
                 1.000, 0.667, 0.500,
                 1.000, 1.000, 0.500,
                 0.000, 0.333, 1.000,
                 0.000, 0.667, 1.000,
                 0.000, 1.000, 1.000,
                 0.333, 0.000, 1.000,
                 0.333, 0.333, 1.000,
                 0.333, 0.667, 1.000,
                 0.333, 1.000, 1.000,
                 0.667, 0.000, 1.000,
                 0.667, 0.333, 1.000,
                 0.667, 0.667, 1.000,
                 0.667, 1.000, 1.000,
                 1.000, 0.000, 1.000,
                 1.000, 0.333, 1.000,
                 1.000, 0.667, 1.000,
                 0.167, 0.800, 0.000,
                 0.333, 0.000, 0.000,
                 0.500, 0.000, 0.000,
                 0.667, 0.000, 0.000,
                 0.833, 0.000, 0.000,
                 1.000, 0.000, 0.000,
                 0.000, 0.667, 0.400,
                 0.000, 0.333, 0.000,
                 0.000, 0.500, 0.000,
                 0.000, 0.667, 0.000,
                 0.000, 0.833, 0.000,
                 0.000, 1.000, 0.000,
                 0.000, 0.000, 0.167,
                 0.000, 0.000, 0.333,
                 0.000, 0.000, 0.500,
                 0.000, 0.000, 0.667,
                 0.000, 0.000, 0.833,
                 0.000, 0.000, 1.000,
                 0.000, 0.200, 0.800,
                 0.143, 0.143, 0.543,
                 0.286, 0.286, 0.286,
                 0.429, 0.429, 0.429,
                 0.571, 0.571, 0.571,
                 0.714, 0.714, 0.714,
                 0.857, 0.857, 0.857,
                 0.000, 0.447, 0.741,
                 0.50, 0.5, 0]

export_config:
    input_res: dataset_config.input_res_test
    ckpt_file: "./ckpt_file.ckpt"
    export_format: "MINDIR"
    export_name: "CenterNet_ObjectDetection"

---
# Help description for each configuration
enable_modelarts: "Whether training on modelarts, default: False"
data_url: "Url for modelarts"
train_url: "Url for modelarts"
data_path: "The location of the input data."
output_path: "The location of the output file."
device_target: "Running platform, default is Ascend."
enable_profiling: 'Whether enable profiling while training, default: False'

distribute: "Run distribute, default is false."
need_profiler: "Profiling to parsing runtime info, default is false."
profiler_path: "The path to save profiling data"
epoch_size: "Epoch size, default is 1."
train_steps: "Training Steps, default is -1, i.e. run all steps according to epoch number."
device_id: "Device id, default is 0."
device_num: "Use device nums, default is 1."
enable_save_ckpt: "Enable save checkpoint, default is true."
do_shuffle: "Enable shuffle for dataset, default is true."
enable_data_sink: "Enable data sink, default is true."
data_sink_steps: "Sink steps for each epoch, default is 1."
save_checkpoint_path: "Save checkpoint path"
load_checkpoint_path: "Load checkpoint file path"
save_checkpoint_steps: "Save checkpoint steps, default is 1000."
save_checkpoint_num: "Save checkpoint numbers, default is 1."
mindrecord_dir: "Mindrecord dataset files directory"
mindrecord_prefix: "Prefix of MindRecord dataset filename."
visual_image: "Visulize the ground truth and predicted image"
save_result_dir: "The path to save the predict results"

data_dir: "Dataset directory, the absolute image path is joined by the data_dir, and the relative path in anno_path"
run_mode: "test or validation, default is test."
enable_eval: "Whether evaluate accuracy after prediction"

---
device_target: ['Ascend', 'GPU']
distribute: ["true", "false"]
need_profiler: ["true", "false"]
enable_save_ckpt: ["true", "false"]
do_shuffle: ["true", "false"]
enable_data_sink: ["true", "false"]
export_format: ["MINDIR"]
