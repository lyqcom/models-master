# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: False
data_url: ""
train_url: ""
checkpoint_url: ""
mindrecord_dir: ""
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
device_target: GPU
enable_profiling: False

# ==============================================================================
# config
img_width: 1280
img_height: 768
keep_ratio: True
flip_ratio: 0.5
expand_ratio: 1.0

# anchor
anchor_scales: [4, 8, 16, 32, 64]
anchor_ratios: [0.5, 1.0, 2.0]
anchor_strides: [16]
num_anchors: 15

# resnet
resnet_block: [3, 4, 23, 3]
resnet_in_channels: [64, 256, 512, 1024]
resnet_out_channels: [256, 512, 1024, 2048]

# roi pooling
k: 7
group_size: 7
n_cls_reg: 2
roi_nums_test: 2000


# rpn
rpn_in_channels: 1024
rpn_feat_channels: 1024
rpn_loss_cls_weight: 1.0
rpn_loss_reg_weight: 1.0
rpn_cls_out_channels: 1
rpn_target_means: [0., 0., 0., 0.]
rpn_target_stds: [1.0, 1.0, 1.0, 1.0]

# bbox_assign_sampler
neg_iou_thr: 0.3
pos_iou_thr: 0.7
min_pos_iou: 0.3
num_gts: 128
num_expected_neg: 256
num_expected_pos: 128

# proposal
activate_num_classes: 2
use_sigmoid_cls: True

# bbox_assign_sampler_stage2
neg_iou_thr_stage2: 0.5
pos_iou_thr_stage2: 0.5
min_pos_iou_stage2: 0.5
num_bboxes_stage2: 2000
num_expected_pos_stage2: 128
num_expected_neg_stage2: 512
num_expected_total_stage2: 512

# rfcn_loss
rfcn_loss_cls_weight: 1
rfcn_loss_reg_weight: 1
rfcn_target_means: [0., 0., 0., 0.]
rfcn_target_stds: [0.1, 0.1, 0.2, 0.2]

# train proposal
rpn_proposal_nms_across_levels: False
rpn_proposal_nms_pre: 2000
rpn_proposal_nms_post: 2000
rpn_proposal_max_num: 2000
rpn_proposal_nms_thr: 0.7
rpn_proposal_min_bbox_size: 0

# test proposal
rpn_nms_across_levels: False
rpn_nms_pre: 1000
rpn_nms_post: 1000
rpn_max_num: 1000
rpn_nms_thr: 0.7
rpn_min_bbox_min_size: 0
test_score_thr: 0.05
test_iou_thr: 0.5
test_max_per_img: 100
test_batch_size: 2

rpn_head_use_sigmoid: True
rpn_head_weight: 1.0

# LR
base_lr: 0.01
warmup_step: 500
warmup_ratio: 0.0625
sgd_step: [8, 11]
sgd_momentum: 0.9

# train
batch_size: 2
loss_scale: 256
momentum: 0.91
weight_decay: 0.00001
epoch_size: 26
interval: 1
save_checkpoint: True
save_checkpoint_epochs: 1
keep_checkpoint_max: 5
save_checkpoint_path: "./"

# Number of threads used to process the dataset in parallel
num_parallel_workers: 8
# Parallelize Python operations with multiple worker processes
python_multiprocessing: True
coco_root: ""
train_data_type: "train2014"
val_data_type: "val2014"
instance_set: "annotations/instances_{}.json"

coco_classes: ['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
                     'train', 'truck', 'boat', 'traffic light', 'fire hydrant',
                     'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',
                     'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
                     'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
                     'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
                     'kite', 'baseball bat', 'baseball glove', 'skateboard',
                     'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
                     'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
                     'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
                     'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
                     'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
                     'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
                     'refrigerator', 'book', 'clock', 'vase', 'scissors',
                     'teddy bear', 'hair drier', 'toothbrush']
other_classes: ['']

num_classes: 81
prefix: ""

# annotations file(json format or user defined text format)
anno_path: ''
image_dir: ''

# train.py Rfcn training
run_distribute: False
dataset: "coco"
pre_trained: ""
device_id: 0
device_num: 1
rank_id: 0
backbone: 'resnet_v1_101'

# eval.py Rfcn evaluation
checkpoint_path: ""

---
# Config description for each option
enable_modelarts: 'Whether training on modelarts, default: False'
data_url: 'Dataset url for obs'
train_url: 'Training output url for obs'
data_path: 'Dataset path for local'
output_path: 'Training output path for local'
result_dir: "result files path."
label_dir: "image file path."

device_target: "device where the code will be implemented, default is GPU"
file_name: "output file name."
dataset: "Dataset, either cifar10 or imagenet2012"
parameter_server: 'Run parameter server train'
width: 'input width'
height: 'input height'
enable_profiling: 'Whether enable profiling while training, default: False'
run_distribute: 'Run distribute, default is false.'
do_train: 'Do train or not, default is true.'
pre_trained: 'Pretrained checkpoint path'
device_id: 'Device id, default is 0.'
device_num: 'Use device nums, default is 1.'
rank_id: 'Rank id, default is 0.'
file_format: 'file format'
ann_file: "Ann file, default is val.json."
checkpoint_path: "Checkpoint file path."
result_path: "result file path."
backbone: "backbone network name, resnet_v1_101"
interval: "val interval"

---
device_target: ['Ascend', 'GPU', 'CPU']
file_format: ["AIR", "ONNX", "MINDIR"]
dataset_name: ["cifar10", "imagenet2012"]
