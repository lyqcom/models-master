general:
    backend: mindspore

pipeline: [eval]

eval:
    pipe_step:
        type: TrainPipeStep
        models_folder: ~
    trainer:
        type: Trainer
        with_train: False
        callbacks: ESRTrainerCallback
        node_num: 20
        epochs: 15000
        optimizer:
            type: Adam
            params:
                lr: 0.0001
        lr_scheduler:
            type: MultiStepLR
            params:
                milestones: [8000,12000,13500,14500]
                gamma: 0.5
        loss:
            type: L1Loss
        metric:
            type: PSNR
            params:
                scale: 2 
                max_rgb: 255
        scale: 2
        seed: 10
        range:
            node_num: 20
    evaluator:
       type: Evaluator
       host_evaluator:
           type: HostEvaluator
           metric:
               type: PSNR

    dataset:
        type: DIV2K
        train:
            root_HR: /cache/datasets/DIV2K/div2k_train/hr
            root_LR: /cache/datasets/DIV2K/div2k_train/lr
            upscale: 2
            crop: 64
            hflip: true
            vflip: true
            rot90: true 
            shuffle: true
            batch_size: 16
            fixed_size: true
        test:
            root_HR: /cache/datasets/DIV2K/div2k_valid/hr
            root_LR: /cache/datasets/DIV2K/div2k_valid/lr
            upscale: 2
            fixed_size: true
            crop: 64
