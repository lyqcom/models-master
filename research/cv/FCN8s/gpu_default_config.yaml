# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unlesee you know exactly what you are doing)
enable_modelarts: False
# url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
device_target: "GPU"
enable_profiling: False
checkpoint_path: "./checkpoint/"
checkpoint_file: "./checkpoint/.ckpt"
# ======================================================================================
# common options

crop_size: 512
image_mean: [103.53, 116.28, 123.675]
image_std: [57.375, 57.120, 58.395]
ignore_label: 255
num_classes: 21
model: "FCN8s"
parallel_mode: "data_parallel"

# ======================================================================================
# Training options
train_batch_size: 8
min_scale: 0.5
max_scale: 2.0
data_file: "./vocaug_local_mindrecords/vocaug_local_mindrecords.mindrecords"  # change to your own path of train data

# optimizer
train_epochs: 500
base_lr: 0.005
loss_scale: 1024

# model
ckpt_vgg16: "./vgg16_predtrain.ckpt"  # change to your own path of backbone pretrain
ckpt_pre_trained: ""
save_steps: 330
keep_checkpoint_max: 5
ckpt_dir: "./ckpt"


# ======================================================================================
# Eval options
eval_batch_size: 16
data_root: "./VOCdevkit/VOC2012"    # change to your own path of val data
data_lst: "./VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt"    # change to your own path of val data list
scales: [1.0]
flip: False
freeze_bn: False
ckpt_file: "./FCN8s_1-500_220.ckpt"    # change to your own path of evaluate model


---
# Help description for each configuration
enable_modelarts: "Whether training on modelarts default: False"
data_url: "Url for modelarts"
train_url: "Url for modelarts"
data_path: "The location of input data"
output_pah: "The location of the output file"
device_target: "device id of GPU or Ascend. (Default: None)"
enable_profiling: "Whether enable profiling while training default: False"
crop_size: "crop_size"
image_mean: "image_mean"
image_std: "image std"
ignore_label: "ignore label"
num_classes: "number of classes"
model: "select model"
data_file: "path of train data"
train_batch_size: "train_batch_size"
min_scale: "min scales of train"
max_scale: "max scales of train"
train_epochs: "train epoch"
base_lr: "base lr"
loss_scale: "loss scales"
ckpt_vgg16: "backbone pretrain"
ckpt_pre_trained: "model pretrain"
data_root: "root path of val data"
eval_batch_size: "eval batch size"
data_lst: "list of val data"
scales: "scales of evaluation"
flip: "freeze bn"
ckpt_file: "model to evaluate"