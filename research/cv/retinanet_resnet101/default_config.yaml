# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: False
data_url: ""
train_url: ""
checkpoint_url: ""
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
device_target: Ascend
enable_profiling: False
need_modelarts_dataset_unzip: True
modelarts_dataset_unzip_name: "cocodataset"

# ==============================================================================
img_shape: [600, 600]
num_retinanet_boxes: 67995
match_thershold: 0.5
softnms_sigma: 0.5
nms_thershold: 0.6
min_score: 0.1
max_boxes: 100

# learing rate settings
global_step: 0
lr_init: 0.000001 # 1e-6
lr_end_rate: 0.005 # 5e-3
warmup_epochs1: 2
warmup_epochs2: 5
warmup_epochs3: 23
warmup_epochs4: 60
warmup_epochs5: 160
momentum: 0.9
weight_decay: 0.00015 # 1.5e-4

# network
num_default: [9, 9, 9, 9, 9]
extras_out_channels: [256, 256, 256, 256, 256]
feature_size: [75, 38, 19, 10, 5]
aspect_ratios:
- [0.5, 1.0, 2.0]
- [0.5, 1.0, 2.0]
- [0.5, 1.0, 2.0]
- [0.5, 1.0, 2.0]
- [0.5, 1.0, 2.0]
steps: [8, 16, 32, 64, 128]
anchor_size: [32, 64, 128, 256, 512]
prior_scaling: [0.1, 0.2]
gamma: 2.0
alpha: 0.75

# `mindrecord_dir` and `coco_root` are better to use absolute path.
mindrecord_dir: "/cache/train/MindRecord_COCO"
coco_root: "/cache/data"
train_data_type: "train2017"
val_data_type: "val2017"
instances_set: "annotations/instances_{}.json"
coco_classes: ['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
                     'train', 'truck', 'boat', 'traffic light', 'fire hydrant',
                     'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',
                     'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
                     'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
                     'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
                     'kite', 'baseball bat', 'baseball glove', 'skateboard',
                     'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
                     'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
                     'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
                     'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
                     'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
                     'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
                     'refrigerator', 'book', 'clock', 'vase', 'scissors',
                     'teddy bear', 'hair drier', 'toothbrush']
num_classes: 81
# The annotation.json position of voc validation dataset.
voc_root: ""
# voc original dataset.
voc_dir: ""
# if coco or voc used, `image_dir` and `anno_path` are useless.
image_dir: ""
anno_path: ""
save_checkpoint: True
keep_checkpoint_max: 30
save_checkpoint_path: "./model"
finish_epoch: 0
checkpoint_path: "/cache/train/model/retinanet-400_458.ckpt"

# train.py retinanet training
only_create_dataset: False
distribute: False
device_id: 0
device_num: 1
lr: 0.1
mode: "sink"
dataset: "coco"
epoch_size: 500
batch_size: 32
pre_trained: ''
pre_trained_epoch_size: 0
save_checkpoint_epochs: 1
loss_scale: 1024
filter_weight: False
run_platform: "Ascend"

# export.py retinanet evaluation
file_format: "MINDIR"
# batch_size: 1
file_name: "retinanet"

# postprocess.py retinanet evaluation
result_path: ''
img_path: ''
img_id_file: ''

---
# Config description for each option
only_create_dataset: 'If set it true, only create Mindrecord, default is False.'
distribute: 'Run distribute, default is False.'
device_id: 'Device id, default is 0.'
device_num: 'Use device nums, default is 1.'
lr: 'Learning rate, default is 0.1.'
mode: 'Run sink mode or not, default is sink.'
dataset: 'Dataset, default is coco.'
epoch_size: 'Epoch size, default is 500.'
batch_size: 'Batch size, default is 32.'
pre_trained: 'Pretrained Checkpoint file path.'
pre_trained_epoch_size: 'Pretrained epoch size.'
save_checkpoint_epochs: 'Save checkpoint epochs, default is 1.'
loss_scale: 'Loss scale, default is 1024.'
filter_weight: 'Filter weight parameters, default is False.'
run_platform: 'Run platform, only support Ascend and GPU.'
file_format: 'file format'
file_name: 'output file name.'
result_path: 'result file path.'
img_path: 'image file path.'
img_id_file: 'image id file.'

enable_modelarts: 'Whether training on modelarts, default: False'
data_url: 'Dataset url for obs'
train_url: 'Training output url for obs'
data_path: 'Dataset path for local'

---
run_platform: ['Ascend', 'GPU']
file_format: ["AIR", "MINDIR"]
